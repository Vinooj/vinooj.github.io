<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Step 3: Feature Selection</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;800&family=Fira+Code&display=swap" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Inter', sans-serif; background: #f0f4f8; padding: 20px; color: #333; }
        .container { max-width: 1400px; margin: 0 auto; background: #ffffff; border-radius: 20px; padding: 30px; box-shadow: 0 15px 30px rgba(0, 0, 0, 0.08); }
        .page-header { background: linear-gradient(135deg, #a8dadc, #457b9d); color: white; padding: 20px 30px; border-radius: 15px; margin-bottom: 30px; font-size: 1.8rem; font-weight: 600; box-shadow: 0 5px 15px rgba(0, 0, 0, 0.15); }
        .tree-container { background: #fdfdfd; border-radius: 15px; padding: 30px; margin: 20px 0; box-shadow: 0 8px 20px rgba(0, 0, 0, 0.05); border: 1px solid #e0e7eb; }
        .tree { font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.6; color: #333; white-space: pre-wrap; overflow-x: auto; }
        .priority-3 { color: #457b9d; font-weight: bold; }
        .package { background: #a8dadc; color: #333; padding: 2px 8px; border-radius: 12px; font-size: 12px; font-weight: 500; margin: 0 3px; display: inline-block; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .method-description { font-style: italic; color: #777; margin-left: 20px; font-size: 12px; }
        .highlight { background: #ffe6a7; padding: 2px 5px; border-radius: 3px; font-weight: bold; color: #333; }
        .importance-marker { font-size: 0.8em; font-weight: bold; padding: 2px 6px; border-radius: 8px; margin-left: 8px; vertical-align: middle; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
        .importance-marker.level-5 { background-color: #fcebeb; color: #e63946; } .importance-marker.level-4 { background-color: #fff3e0; color: #f4a261; } .importance-marker.level-3 { background-color: #e0f2f7; color: #457b9d; } .importance-marker.level-2 { background-color: #f1eff8; color: #8d86c9; } .importance-marker.level-1 { background-color: #e6f5e6; color: #6a994e; }
        .back-link { display: inline-block; text-align: center; margin-top: 30px; padding: 10px 20px; text-decoration: none; color: white; font-weight: bold; background: #457b9d; border-radius: 10px; transition: background 0.3s ease; }
        .back-link:hover { background: #e63946; }
    </style>
</head>
<body>
    <div class="container">
        <div class="page-header">Step 3: Feature Selection</div>
        <div class="tree-container">
            <div class="tree">
<span class="priority-3">3. FEATURE SELECTION (MEDIUM-HIGH IMPORTANCE - Third Priority)</span> <span class="importance-marker level-3">(3/5)</span>
│   ├── <span class="highlight">Filter Methods (Univariate)</span> <span class="importance-marker level-4">(4/5)</span>
│   │   ├── Statistical Tests <span class="importance-marker level-4">(4/5)</span>
│   │   │   ├── Chi-Square Test <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.chi2</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.SelectKBest(chi2)</span>
│   │   │   │   └── <span class="method-description">✓ For categorical features vs categorical target</span>
│   │   │   ├── ANOVA F-Test <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.f_classif</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.f_regression</span>
│   │   │   │   └── <span class="method-description">✓ For numerical features vs categorical/numerical target</span>
│   │   │   ├── Mutual Information <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.mutual_info_classif</span>
│   │   │   │   ├── <span class="package">sklearn.feature_selection.mutual_info_regression</span>
│   │   │   │   └── <span class="method-description">✓ Captures non-linear relationships</span>
│   │   │   └── Kendall's Tau <span class="importance-marker level-2">(2/5)</span>
│   │   │       ├── <span class="package">scipy.stats.kendalltau</span>
│   │   │       └── <span class="method-description">✓ Non-parametric correlation measure</span>
│   │   ├── Correlation-Based <span class="importance-marker level-4">(4/5)</span>
│   │   │   ├── Pearson Correlation <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">pandas.DataFrame.corr()</span>
│   │   │   │   ├── <span class="package">numpy.corrcoef()</span>
│   │   │   │   ├── <span class="package">scipy.stats.pearsonr()</span>
│   │   │   │   └── <span class="method-description">✓ Linear relationships, normally distributed data</span>
│   │   │   ├── Spearman Correlation <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">scipy.stats.spearmanr()</span>
│   │   │   │   ├── <span class="package">pandas.DataFrame.corr(method='spearman')</span>
│   │   │   │   └── <span class="method-description">✓ Monotonic relationships, rank-based</span>
│   │   │   └── Kendall Correlation <span class="importance-marker level-2">(2/5)</span>
│   │   │       ├── <span class="package">scipy.stats.kendalltau()</span>
│   │   │       └── <span class="method-description">✓ Robust to outliers, small sample sizes</span>
│   │   └── Variance-Based <span class="importance-marker level-4">(4/5)</span>
│   │       ├── Low Variance Filter <span class="importance-marker level-4">(4/5)</span>
│   │       │   ├── <span class="package">sklearn.feature_selection.VarianceThreshold</span>
│   │       │   └── <span class="method-description">✓ Removes features with low variance (near-constant)</span>
│   │       └── High Correlation Filter <span class="importance-marker level-4">(4/5)</span>
│   │           ├── <span class="package">Custom implementation with pandas.DataFrame.corr()</span>
│   │           └── <span class="method-description">✓ Removes highly correlated features (multicollinearity)</span>
│   │
│   ├── <span class="highlight">Wrapper Methods (Model-Based)</span> <span class="importance-marker level-3">(3/5)</span>
│   │   ├── Forward Selection <span class="importance-marker level-3">(3/5)</span>
│   │   │   ├── <span class="package">sklearn.feature_selection.SequentialFeatureSelector(direction='forward')</span>
│   │   │   ├── <span class="package">mlxtend.feature_selection.SequentialFeatureSelector</span>
│   │   │   └── <span class="method-description">✓ Starts empty, adds features iteratively</span>
│   │   ├── Backward Elimination <span class="importance-marker level-3">(3/5)</span>
│   │   │   ├── <span class="package">sklearn.feature_selection.SequentialFeatureSelector(direction='backward')</span>
│   │   │   ├── <span class="package">mlxtend.feature_selection.SequentialFeatureSelector</span>
│   │   │   └── <span class="method-description">✓ Starts with all features, removes iteratively</span>
│   │   ├── Recursive Feature Elimination (RFE) <span class="importance-marker level-4">(4/5)</span>
│   │   │   ├── <span class="package">sklearn.feature_selection.RFE</span>
│   │   │   ├── <span class="package">sklearn.feature_selection.RFECV</span>
│   │   │   └── <span class="method-description">✓ Recursively eliminates least important features</span>
│   │   └── Genetic Algorithms <span class="importance-marker level-2">(2/5)</span>
│   │       ├── <span class="package">sklearn-genetic-opt.GAFeatureSelectionCV</span>
│   │       ├── <span class="package">DEAP</span>
│   │       └── <span class="method-description">✓ Evolutionary approach to feature selection</span>
│   │
│   ├── <span class="highlight">Embedded Methods (Intrinsic)</span> <span class="importance-marker level-4">(4/5)</span>
│   │   ├── Tree-Based Importance <span class="importance-marker level-5">(5/5)</span>
│   │   │   ├── Random Forest Importance <span class="importance-marker level-5">(5/5)</span>
│   │   │   │   ├── <span class="package">sklearn.ensemble.RandomForestClassifier.feature_importances_</span>
│   │   │   │   ├── <span class="package">sklearn.ensemble.RandomForestRegressor.feature_importances_</span>
│   │   │   │   └── <span class="method-description">✓ Gini/entropy-based importance, handles interactions</span>
│   │   │   ├── Extra Trees Importance <span class="importance-marker level-4">(4/5)</span>
│   │   │   │   ├── <span class="package">sklearn.ensemble.ExtraTreesClassifier.feature_importances_</span>
│   │   │   │   └── <span class="method-description">✓ More randomized than Random Forest</span>
│   │   │   ├── XGBoost Importance <span class="importance-marker level-5">(5/5)</span>
│   │   │   │   ├── <span class="package">xgboost.XGBClassifier.feature_importances_</span>
│   │   │   │   ├── <span class="package">xgboost.plot_importance()</span>
│   │   │   │   └── <span class="method-description">✓ Gain, weight, cover importance metrics</span>
│   │   │   ├── LightGBM Importance <span class="importance-marker level-5">(5/5)</span>
│   │   │   │   ├── <span class="package">lightgbm.LGBMClassifier.feature_importances_</span>
│   │   │   │   ├── <span class="package">lightgbm.plot_importance()</span>
│   │   │   │   └── <span class="method-description">✓ Split-based importance, fast training</span>
│   │   │   └── CatBoost Importance <span class="importance-marker level-4">(4/5)</span>
│   │   │       ├── <span class="package">catboost.CatBoostClassifier.feature_importances_</span>
│   │   │       └── <span class="method-description">✓ Handles categorical features natively</span>
│   │   └── Regularization-Based <span class="importance-marker level-4">(4/5)</span>
│   │       ├── L1 Regularization (Lasso) <span class="importance-marker level-5">(5/5)</span>
│   │       │   ├── <span class="package">sklearn.linear_model.Lasso</span>
│   │       │   └── <span class="method-description">✓ Drives coefficients to zero, performs feature selection</span>
│   │       ├── L2 Regularization (Ridge) <span class="importance-marker level-4">(4/5)</span>
│   │       │   ├── <span class="package">sklearn.linear_model.Ridge</span>
│   │       │   └── <span class="method-description">✓ Shrinks coefficients, prevents overfitting, no explicit selection</span>
│   │       └── Elastic Net (L1+L2) <span class="importance-marker level-4">(4/5)</span>
│   │           ├── <span class="package">sklearn.linear_model.ElasticNet</span>
│   │           └── <span class="method-description">✓ Combines L1 and L2, robust to correlated features</span>
│   │
│   └── <span class="highlight">Hybrid Methods</span> <span class="importance-marker level-3">(3/5)</span>
│       ├── SelectFromModel <span class="importance-marker level-3">(3/5)</span>
│       │   ├── <span class="package">sklearn.feature_selection.SelectFromModel</span>
│       │   └── <span class="method-description">✓ Uses model's feature importance/coefficients to select features</span>
│       └── Boruta Algorithm <span class="importance-marker level-2">(2/5)</span>
│           ├── <span class="package">boruta_py.BorutaPy</span>
│           └── <span class="method-description">✓ All-relevant feature selection using Random Forest</span>
            </div>
        </div>
        <a href="../ml_pipeline_overview.html" class="back-link">← Back to Main Pipeline</a>
    </div>
</body>
</html>